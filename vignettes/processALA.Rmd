---
title: "processALA: An R-package to help manage ALA data for plant species"
author: "Peter D. Wilson"
date: "30 November 2021"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{processALA: An R-package to help manage ALA data for plant species}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
```{r, include = FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
```

**processALA** is an _**R**_-package developed to make downloading and cleaning occurrence data for plant species from the Atlas of Living Australia (ALA) a simple process. By stream-lining the way you interact with ALA, the package should allow you to check taxonomic names and obtain useful occurrence data "live". That is, you can integrate the process of downloading the latest occurrence data into R-scripts and run them whenever you need up-to-date data. Alternatively, you can use the functions included in the package to run data download and cleaning to periodically refresh sets of local stored data files. This second approach can be the most efficient method because data from ALA changes infrequently, which is particularly true of herbarium data which is the highest value data for most use cases we encounter. In addition, live interrogation of ALA depends on a good internet connection and naturally introduces delays to running scripts.

A major re-working of **processALA** was undertaken in late November 2021 to transition from using the package **ALA4R** to the package **galah**. **ALA4R** is to be retired at the end of 2021 in favour of it's replacement package **galah**.

To view and download the source go to: https://github.com/peterbat1/processALA.

To install the package in your local _**R**_ installation, it is easiest to ensure that the following dependencies are installed in your local _**R**_ system:

* galah
* httr
* dplyr
* ozmaps (for running the worked example in this vignette)

It is most productive to install these packages using the package management features in R-Studio as they pull in a fair number of dependencies and it is a pain to work through that list manually before you finally install the target package.

To complete the installation of **processALA**, ensure that the package **remotes** is installed from CRAN, then enter the following command at the prompt in the _**R**_ console:

```{r eval=FALSE}
remotes::install_github("peterbat1/processALA", build_vignettes = TRUE)
```

As with any _**R**_-package installed on your system, your scripts must begin with:

```{r setup}
library(processALA)
```

## A bit about ALA and accessing data

The Atlas of Living Australia is many things:

* A gateway to a comprehensive collection of occurrence records of many types including herbarium records from Australia and New Zealand supplied by Australia's Virtual Herbarium (which is hosted by ALA)
* The source of an accepted National Species List, and repository of taxonomic and nomenclatural information which for plants is formed by the Australian Plant Name Index (APNI) and the Australian Plant Census (APC) hosted by ALA on behalf of the Council of Heads of Australasian Herbaria (CHAH)
* The Australian node of the Global Biodiversity Information Facility (GBIF)

ALA is an important source of occurrence data and taxonomic information which can be accessed through a web interface. However, for many researchers this can be cumbersome, particularly when many taxa must be processed. Fortunately ALA also provides an API or Application Programming Interface which lets you perform searches and retrieve records using scripts. This makes it easier to process lists of taxa or make periodic updates of information. You can find out more about the ALA API [here](https://api.ala.org.au).

ALA also maintains an _**R**_-package, **galah**, to make it very easy to use the ALA API. The functions within that package allow us to make use of the API without having to learn the ins and outs of composing query strings and the application of web access tools such as _curl_ and _wget_. (Of course, if you're into such things there are fun times ahead for you if you want to work directly with curl or wget calls.)

The package **processALA** adds another level of refinement. It highly automates key steps in the retrieval and processing of ALA data by utilising a few key functions in the **galah** package and adds functions to assist in data cleaning. In addition, it adds a mechanism to access some ALA API functions not exposed in **galah**.

There are three stages to obtaining occurrence data from ALA:

* resolving your taxa to those available on the National Species List
* downloading occurrence data
* cleaning occurrence data

Three key functions in **processALA** have been designed to implement each step. The functions are:

* *checkTaxonName()*
* *fetchALAdata()* and
* *filterALAdata()*

The focus of this vignette is to guide you in applying them to fetching occurrence records and making them fit for further use.

## Handling taxonomic names

The ALA API provides a number of functions which allow you to interrogate APNI and APC to resolve plant names to a matching accepted name from APC. A function in **galah**, _select_taxa()_ is available to determine the status of a name and provide a few details associated with it. The **processALA** function _checkTaxonName()_ uses that function to check a name you have supplied and also makes a few calls to ALA API functions not accessible via **galah**. The returned information is useful for further processing of records, and for creating or updating a taxonomic table for your work.

Steps to checking a name include:

1. Call _checkTaxonName()_ with your prospective name as the first parameter and assign the result to an object

2. Examine data elements in the result object and use them to determine the next step

For example:

```{r}
ans <- checkTaxonName("Acacia linifolia")
ans
```

The result object **ans** is a 1-row data frame with the following columns or data elements:

Element | Data type and contents
--------|-----------------------
isValid | Logical. Is the taxonomic name found in the Australian Plant Name Index (APNI); to be listed in APNI a taxonomic name must have been formally defined and applied in a publication to collected material.
isAccepted | Logical. Is the searched for taxonomic name accepted by the Australian Plant Census (APC) as an accepted name associated with a taxonomic concept.
searchName | Character (string). Taxonomic name searched for.
acceptedName | Character (string). The accepted taxon name corresponding to the name searched for.
fullAcceptedName | Character (string). Binomial/trinomial + author of the accepted taxon name.
acceptedGUID | Character (string). The ALA Globally Unique Identifier or GUID; a numeric string uniquely indexing a taxonomic concept in the Australian Plant Name Index (APNI) component of the National Species List (NSL). No match results in a GUID of "Not_accepted" being returned.
acceptedFullGUID | Character (string). The full URL form of the GUID: stored as a convenience to speed calls to the ALA API, and assist maintenance of code.
formattedAcceptedName | Character (string). Full taxonomic name (i.e. binomial/trinomial + author) with simple HTML mark-up to italicise the binomial/trinomial part.
taxonomicRank | Character (string). Taxonomic rank of the accepted name.
parentGUID | Character (string). Full GUID of the taxonomic parent of the accepted taxon.
parentName | Character (string). Name of the taxonomic parent of the accepted taxon.
parentTaxonomicRank | Character (string). Taxonomic rank of the parent.
synonyms | Character (string). A semi-colon separated list of taxonomic synonyms of the accepted taxon.
apcFamily | Character (string). Family of the accepted taxon according to APC.

A name is "valid" in the sense used for **processALA** when it is found in an APNI record. However, the name you search on may not be the name which is currently applied to the taxon according to APC. APC lists _formally accepted_ taxonomic names whereas APNI lists all published names associated with the currently accepted name listed on APC. Thus, we can be in one of three states after a call to _checkTaxonName()_ based on the logical flags _isValid_ and _isAccepted_:

isValid | isAccepted | Meaning
--------|------------|----------
FALSE | FALSE | You have found nothing matching any name listed in APNI and, naturally, there is no corresponding accepted name in APC.
TRUE  | FALSE | Your search name is listed in APNI but it is not the accepted name for the taxon according to APC. The corresponding APC accepted name will be shown in the _acceptedName_ column of the result. Your search name will be shown as a synonym of the accepted name in the field _synonyms_.
TRUE | TRUE | Congratulations! The name you searched for is listed in APNI and is the accepted name according  to APC. In this case, _searchName_ and _acceptedName_ will be identical.

Here are some quick examples of calls to _checkTaxonName()_ resulting in each state:

### FALSE : FALSE
```{r}
ans <- checkTaxonName("Greenus plantus")
ans
```

### TRUE : FALSE
```{r}
ans <- checkTaxonName("Acacia abietina")
ans
```

### TRUE : TRUE
```{r}
ans <- checkTaxonName("Acacia linifolia")
ans
```

Hopefully you can see the potential for using the information returned by _checkTaxonName()_. For example:

- You should be able to write some _**R**_ code to flag bad names and have your script act accordingly.

- You can easily add a list of synonyms to your output files or documents by using text stored in the _synonyms_ field of the object returned by _checkTaxonName()_.

- You can readily insert the full accepted taxonomic names into output, including using the HTML-formatted version in web-based outputs (e.g. _**R**_ Shiny apps).

## Downloading occurrence data

The next step is downloading occurrence data for an accepted taxonomic name. This is performed by the function _fetchALAdata()_ which uses the function _ala_occurrences()_ in the package **galah**. Note that the parameter _doNameCheck_ is by default set to **TRUE** so that a name check is performed before attempting a data download. However, if a prior call has been made to _checkTaxonName()_, then this parameter may be set to **FALSE** and so some small quantum of time may be saved.

The **galah** function _ala_occurrences()_ returns a data frame which is the table of occurrence data. _fetchALAdata()_ saves the downloaded data in the specified output folder using the following naming convention: "Genus_specificEpithet.csv".

Within the raw data table maybe found occurrence records for several record types which are indicated in the field _basisOfRecord_. The record types include the following:

basisOfRecord | Interpretation
--------------|-----------------
PreservedSpecimen | Herbarium records passed into ALA from the consortium of herbaria and museums which supply data to Australasian Virtual Herbarium (AVH) and which is accessed via ALA 
HumanObservation | Human observations which means any record of species occurrence arising from field encounters or observations which did not result in a voucher specimen being lodged in an herbarium. Examples include casual observations by the general public (also sometimes referred to as 'incidental observations'), and data from systematic vegetation surveys. 
Image | An image of a species which is supplied with geo-coordinates. There are typically few of these encountered in most data downloads.
LivingSpecimen | A form of human observation or incidental observation referring to a specimen in a living collection such as a botanic garden or arboretum.
<empty> | A small fraction of records have the basisOfRecord field empty!

The downloaded occurrence data represents **raw** ALA occurrence data which must be cleaned or filtered before use. However, one preliminary step which _fetchALAdata()_ performs is to split three data types out from the raw data table and place them into separate csv-formatted files.

The first is the _PreservedSpecimen_ records which are saved in a file named "Genus_species_herbariumRecords.csv". Second, _HumanObservation_ records are placed in a similarly named file, "Genus_specificEpithet_humanObservations.csv". Finally, _HumanObservation_ records are parsed to identify records generated by surveys forming part of the NSW Vegetation Information System (VIS). If any are found, they are saved as "Genus_specificEpithet_surveyRecords.csv". Note that these data will also be present in the human observation data.

As a final point, note that image and living specimen data are not currently extracted and saved. These data are however present in the raw data csv file and you may therefore use an _**R**_-script or spreadsheet program (Excel, or LibreOffice Calc on Linux PCs) to extract them if you need access to them.

## Filtering/cleaning ALA data

ALA data is _**dirty**_ data! ALA is just a data aggregation service and web portal transmitting the data as received from data providers. ALA does perform data quality checks and flags as many possible errors as it can, but the data remain as supplied and may include a range of errors. It is up to the end users to either use the quality flags raised by ALA or, preferably, do additional checks to arrive at the cleanest occurrence data possible.

> **It is absolutely essential that you perform data cleaning or filtering before using ALA occurrence data.**

Accumulated experience indicates that there are three types of error present in ALA occurrence data. These include:

* Location errors
* Taxon ID errors
* Record type errors

These three types of error have been identified in many other aggregated biodiversity data sets including the Global Biodiversity Information Facility (GBIF). We will take a quick look at each error type and then see how the function _filterALAdata()_ attempts to remove each of them from raw ALA occurrence data.

### Location errors

Location errors are caused by several conditions:

* missing geo-coordinates (lat/longs)
* inaccurate geo-coordinates: poor data recording by field collectors, data entry errors and, for very old records, imprecise location descriptions which cannot be interpreted to derive meaningful geo-coordinates

Location accuracy and record completeness has improved greatly in recent years and is particularly good from the late 1990s with the increasing use of GPS technology. There is clearly a temporal dimension to geo-coordinate data quality - older records have higher missing coordinate rates and lower accuracy.

_filterALAdata()_ filters missing coordinates by default (i.e. the parameter _removeMissingCoordinates_ = TRUE by default).

A further level of filtering location errors is achieved by calling _filterALAdata()_ with the parameter _filterByJurisdiction_ = TRUE (which is the default). When set, this will cause _filterALAdata()_ to use the **processALA** function _fetchJurisdictionInfo()_ to ask ALA for a list of Australian states and territories in which the taxon is found. Records which fall in a state or territory which is _not_ expected are removed. Any record falling outside Australia (either because it is an herbarium specimen in an Australian herbarium collection but collected outside Australia, or because of a gross coordinate error leading to mid-ocean specimens of terrestrial species!) is also removed in this process.

A list of the states and territories included in _fetchJurisdictionInfo()_, and therefore used by _filterALAdata()_, is provided in the help page for _fetchJurisdictionInfo()_.

### Taxon ID errors

Taxonomic errors may arise from mis-identification in the field which is subsequently not corrected. This type of error can be extremely hard to identify in ALA raw data. In some instances such errors may be apparent when there are a few spatial outliers beyond the expected distribution of a taxon. However, such spatial outliers can also be due to bad geo-coordinates or record type errors.

ALA uses the resources APNI and APC to try and resolve taxonomic names supplied by data providers and in most instances this is highly successful. However, this error-trapping cannot be guaranteed to be 100% effective. Whenever it is feasible, you should review downloaded to look for any anomalies. 

There is also a temporal dimension to taxonomic name errors. Very old specimens may have undergone many complex taxonomic revisions which may make it difficult to assign a modern taxonomic concept to a specimen. This is particularly so when there have been taxonomic splits, and even more problematic when there have been splits for sympatric forms. It the last case, it may be impossible to fix taxonomic problems and you will have to make a call on what to do with taxa in this category and their occurrence data.

_filterALAdata()_ cannot deal directly with these residual taxonomic ID errors but the parameter _filterByJurisdiction_ will move some of them.

### Record-type errors

There are relatively few occurrence records in ALA raw data with bad record types but they do occur and typically generate weird spatial outliers. In my experience, the most apparent record type error is caused by herbarium specimens from cultivated plants which are not correctly identified by ALA's automatic methods.

ALA sets a flag in the database field _occCultivatedEscapee_ which appears to flow from a flag set by the AVH data aggregation process. However, a few data providers seem to be lax in their marking of herbarium specimens taken from cultivated individuals - Canberra and Melbourne are the key offenders - and this requires a second pass over the data by the end user. This additional filter is supplied by _filterALAdata()_ by setting the parameter _filterCultivated_ to TRUE. This is the default setting for the function and removes any record where the term "CULTIVATED" appears in the _locality_ field.

As noted, rogue herbarium specimens from cultivated individuals often show up as inexplicable extreme spatial outliers. This also frequently means they are removed by the jurisdication filter applied by default when you call _filterALAdata()_. Experience suggests that the combined effect of applying _filterCultivated_ = TRUE and _filterByJurisdiction_ = TRUE removes nearly all herbarium samples collected from cultivated plants.

## Worked example

Here is a short script which can be a starting point for developing your own workflows. It first calls _checkTaxonName()_ to determine the status of the species name. Using this result, we determine which of the three states the result represents by comparing the flags _isValid _ and _isAccepted_, and taking appropriate action.

> **Note that this script may take a minute or two to run as it fetches the occurrence data _live_ from ALA.**

```{r eval=FALSE}
library(ozmaps)

# Example of an accepted name
thisTaxon <- "Alectryon coriaceus"

# Example of a synonym which is resolved to the accepted name Callistemon purpurascens because isValid == TRUE but isAccepted == FALSE
# thisTaxon <- "Callistemon sp. Purpurascens (S.Douglas s.n., 15 Dec. 2010)"

# A nonsense name as an example of the final state: isValid == FALSE and isAccepted == FALSE
# thisTaxon <- "Greenus plantus"

cat("Checking", thisTaxon, "with ALA\n")
nameResult <- checkTaxonName(thisTaxon)

if ((nameResult$isValid) && (nameResult$isAccepted))
{
  cat(thisTaxon, "is valid and accepted\n")
  # Taxon name is valid and accepted so full steam ahead...
  fetchALAdata(thisTaxon, doNameCheck = FALSE)
  
  # Apply the default filter set on the downloaded data...
  filterALAdata(thisTaxon, recType = "herbarium", doNameCheck = FALSE)
} else
{
  if (nameResult$isValid)
  {
    thisTaxon <- nameResult$acceptedName
    # Name is present in APNI but is a synonym
    cat("ALA says the accepted name for", thisTaxon, "is", nameResult$acceptedName, "\n")
    fetchALAdata(nameResult$acceptedName, doNameCheck = FALSE)
    filterALAdata(nameResult$acceptedName, recType = "herbarium", doNameCheck = FALSE)
  }
  else
  {
    cat(thisTaxon, "is gibberish according to ALA - check, correct and try again\n")
  }
}

herbDataFile <- paste0(defaultOutputFolder, "/", thisTaxon, "/", gsub(" ", "_", thisTaxon, fixed = TRUE), "_herbariumRecords_filtered.csv")

if (file.exists(herbDataFile))
{
  # Make a map
  d <- read.csv(herbDataFile)
  
  oz()
  points(d$longitude, d$latitude, pch = 16, col = "darkorange")
}
```

